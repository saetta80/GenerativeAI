{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPL73ywBG2D+4S60JEU5IQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fc62504ca9c4eb2ac530e0fb2389973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea7b9ba62b744c51879e0a7bd3e0c14e",
              "IPY_MODEL_46372b53e2dd4cdc8d25db970debb51b",
              "IPY_MODEL_f1e6f64e6ef14689bcf2656630fe2eb5"
            ],
            "layout": "IPY_MODEL_4400cf0419f94527b76ac4b64ea18c79"
          }
        },
        "ea7b9ba62b744c51879e0a7bd3e0c14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749e1276e4414f18b5b9af6c38f29040",
            "placeholder": "​",
            "style": "IPY_MODEL_d1e70ab44eee41928211f968f3893302",
            "value": "Downloading readme: 100%"
          }
        },
        "46372b53e2dd4cdc8d25db970debb51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f26324a4d7254759856e17965f2f5101",
            "max": 130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ef0c0b059dc46919ef2ba2132a60ca9",
            "value": 130
          }
        },
        "f1e6f64e6ef14689bcf2656630fe2eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3223306c0d094e19830190e98e17989f",
            "placeholder": "​",
            "style": "IPY_MODEL_03248dc2255b47a38bb36d39bc09d2ef",
            "value": " 130/130 [00:00&lt;00:00, 8.27kB/s]"
          }
        },
        "4400cf0419f94527b76ac4b64ea18c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749e1276e4414f18b5b9af6c38f29040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e70ab44eee41928211f968f3893302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f26324a4d7254759856e17965f2f5101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef0c0b059dc46919ef2ba2132a60ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3223306c0d094e19830190e98e17989f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03248dc2255b47a38bb36d39bc09d2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e37973091c2420ab80d56d7f814dd54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aad7221a39014ae7a01adb3d866d6408",
              "IPY_MODEL_b8ed48821a944883a32865dd8e80137e",
              "IPY_MODEL_dfc14e3802b846ba9bc22e9ef1c716d4"
            ],
            "layout": "IPY_MODEL_5ad2131f24d9442dbff862b0b80cf0c4"
          }
        },
        "aad7221a39014ae7a01adb3d866d6408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd6a9f9a24a4b89addcced88d93f9be",
            "placeholder": "​",
            "style": "IPY_MODEL_4f2edd2378ef4422b11dd91ba53a19f9",
            "value": "Downloading data files: 100%"
          }
        },
        "b8ed48821a944883a32865dd8e80137e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf399954c96543ba8308c7479c8fd1bd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6e2d09207e74d508376ba3cffc722a9",
            "value": 1
          }
        },
        "dfc14e3802b846ba9bc22e9ef1c716d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a05e87c2c7b7496aa88402b98813b842",
            "placeholder": "​",
            "style": "IPY_MODEL_088c9972e64c41c1b5a51c65d3d1a71e",
            "value": " 1/1 [00:02&lt;00:00,  2.69s/it]"
          }
        },
        "5ad2131f24d9442dbff862b0b80cf0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd6a9f9a24a4b89addcced88d93f9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2edd2378ef4422b11dd91ba53a19f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf399954c96543ba8308c7479c8fd1bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6e2d09207e74d508376ba3cffc722a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a05e87c2c7b7496aa88402b98813b842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088c9972e64c41c1b5a51c65d3d1a71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2902de7d80cf475593fcb96c098aa5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9694644a73fc497288eb9929e2eafad2",
              "IPY_MODEL_523e3372b0e54633a9c54e1dc1b37e77",
              "IPY_MODEL_78f672bf20fb410d964bf182228d5df0"
            ],
            "layout": "IPY_MODEL_191bae36632148df8f2302fb65c4cb28"
          }
        },
        "9694644a73fc497288eb9929e2eafad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79df90f29557483988d34ee894e2615c",
            "placeholder": "​",
            "style": "IPY_MODEL_41ae958052914c53bc907878f7d8f93c",
            "value": "Downloading data: 100%"
          }
        },
        "523e3372b0e54633a9c54e1dc1b37e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f4c0d4c48246eaac1fb2c36e5b7fe4",
            "max": 572766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0037130516cd49ebb0728ec2a2d0ab65",
            "value": 572766
          }
        },
        "78f672bf20fb410d964bf182228d5df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc5601a49974304b9e0a5e202faf7b9",
            "placeholder": "​",
            "style": "IPY_MODEL_f20f1857cc0e43ada30fb2ea4b101658",
            "value": " 573k/573k [00:02&lt;00:00, 216kB/s]"
          }
        },
        "191bae36632148df8f2302fb65c4cb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79df90f29557483988d34ee894e2615c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ae958052914c53bc907878f7d8f93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f4c0d4c48246eaac1fb2c36e5b7fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0037130516cd49ebb0728ec2a2d0ab65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cc5601a49974304b9e0a5e202faf7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20f1857cc0e43ada30fb2ea4b101658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb6cb044f69b4ad48ec7ab525e502edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28687bcca26d4581bfd9fc4aec24082a",
              "IPY_MODEL_0d35ccdb42b846358a5c2410ba6a3b83",
              "IPY_MODEL_fd5b6f78b7fe458fbae87b62923a8b82"
            ],
            "layout": "IPY_MODEL_b36f6c2c0f4040cbbcf449ca66e57c8f"
          }
        },
        "28687bcca26d4581bfd9fc4aec24082a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c74d2a067e1423caacff501f9ef4474",
            "placeholder": "​",
            "style": "IPY_MODEL_2a7f2e3bda504cbea898192fb706b975",
            "value": "Extracting data files: 100%"
          }
        },
        "0d35ccdb42b846358a5c2410ba6a3b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9050dd3f58fd48eab49b8566ca88132d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec89f248d9a64d92bba35bfc6c51d853",
            "value": 1
          }
        },
        "fd5b6f78b7fe458fbae87b62923a8b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf2e316f37f49229752e5bf222b7dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_e2b77886de8d49438c598e0281b0d262",
            "value": " 1/1 [00:00&lt;00:00, 49.81it/s]"
          }
        },
        "b36f6c2c0f4040cbbcf449ca66e57c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c74d2a067e1423caacff501f9ef4474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a7f2e3bda504cbea898192fb706b975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9050dd3f58fd48eab49b8566ca88132d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec89f248d9a64d92bba35bfc6c51d853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccf2e316f37f49229752e5bf222b7dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b77886de8d49438c598e0281b0d262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d5e0ea697004a81972b3c555e67cad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5af083084c840b4ae41f4b16cd5119b",
              "IPY_MODEL_917cf549102e4a6ea7cf16466e4d76b0",
              "IPY_MODEL_781008e1a4f74e05a99e44a728ee496e"
            ],
            "layout": "IPY_MODEL_7aba4e90ffe84c6f9979838895f7a321"
          }
        },
        "c5af083084c840b4ae41f4b16cd5119b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafd43f3a2e64894bc95a96eba4b6c81",
            "placeholder": "​",
            "style": "IPY_MODEL_0d0378148be049979e813e0e6dcd6a30",
            "value": "Generating train split: "
          }
        },
        "917cf549102e4a6ea7cf16466e4d76b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac3299d0fed249cc9ec3e71fd0a00256",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8410dcd185f24f5f8f1f14dbbadc30b2",
            "value": 1
          }
        },
        "781008e1a4f74e05a99e44a728ee496e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d061e3b5c240159627f8d520422373",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0cba6bccec4df9bbd826b1de54bd8f",
            "value": " 1829/0 [00:00&lt;00:00, 31548.31 examples/s]"
          }
        },
        "7aba4e90ffe84c6f9979838895f7a321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafd43f3a2e64894bc95a96eba4b6c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0378148be049979e813e0e6dcd6a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac3299d0fed249cc9ec3e71fd0a00256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8410dcd185f24f5f8f1f14dbbadc30b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99d061e3b5c240159627f8d520422373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0cba6bccec4df9bbd826b1de54bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saetta80/GenerativeAI/blob/main/Llama2_Sentiment_Analysis_Auto_response_generation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation for GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --verbose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1emM9JMaTLA0",
        "outputId": "be175dc4-9e6c-46f1-9530-0fd9e3119f77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.20.tar.gz (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting scikit-build-core[pyproject]>=0.5.1\n",
            "    Using cached scikit_build_core-0.7.0-py3-none-any.whl (136 kB)\n",
            "  Collecting exceptiongroup (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
            "  Collecting packaging>=20.9 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "  Collecting tomli>=1.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Collecting pathspec>=0.10.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "  Collecting pyproject-metadata>=0.5 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached pyproject_metadata-0.7.1-py3-none-any.whl (7.4 kB)\n",
            "  Installing collected packages: tomli, pathspec, packaging, exceptiongroup, scikit-build-core, pyproject-metadata\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  lida 0.0.10 requires fastapi, which is not installed.\n",
            "  lida 0.0.10 requires kaleido, which is not installed.\n",
            "  lida 0.0.10 requires python-multipart, which is not installed.\n",
            "  lida 0.0.10 requires uvicorn, which is not installed.\n",
            "  Successfully installed exceptiongroup-1.2.0 packaging-23.2 pathspec-0.11.2 pyproject-metadata-0.7.1 scikit-build-core-0.7.0 tomli-2.0.1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command pip subprocess to install backend dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting cmake>=3.21\n",
            "    Using cached cmake-3.27.9-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
            "  Collecting ninja>=1.5\n",
            "    Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "  Installing collected packages: ninja, cmake\n",
            "    Creating /tmp/pip-build-env-4q46ugsw/normal/local/bin\n",
            "    changing mode of /tmp/pip-build-env-4q46ugsw/normal/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-4q46ugsw/normal/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-4q46ugsw/normal/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-4q46ugsw/normal/local/bin/ctest to 755\n",
            "  Successfully installed cmake-3.27.9 ninja-1.11.1.1\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  *** scikit-build-core 0.7.0 using CMake 3.27.9 (metadata_wheel)\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m199.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m229.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "  *** scikit-build-core 0.7.0 using CMake 3.27.9 (wheel)\n",
            "  *** Configuring CMake...\n",
            "  loading initial cache file /tmp/tmp5mdzz4wf/build/CMakeInit.txt\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found CUDAToolkit: /usr/local/cuda/include (found version \"11.8.89\")\n",
            "  -- cuBLAS found\n",
            "  -- The CUDA compiler identification is NVIDIA 11.8.89\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  GNU ld (GNU Binutils for Ubuntu) 2.38\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  CMake Warning (dev) at CMakeLists.txt:20 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  CMake Warning (dev) at CMakeLists.txt:29 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  -- Configuring done (3.9s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/tmp5mdzz4wf/build\n",
            "  *** Building project with Ninja...\n",
            "  Change Dir: '/tmp/tmp5mdzz4wf/build'\n",
            "\n",
            "  Run Build Command(s): /tmp/pip-build-env-4q46ugsw/normal/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -v\n",
            "  [1/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/ggml-alloc.c\n",
            "  [2/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/ggml-backend.c\n",
            "  [3/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/ggml-quants.c\n",
            "  [4/23] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/ggml.c\n",
            "  [5/23] cd /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp && /tmp/pip-build-env-4q46ugsw/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=11.4.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/../scripts/gen-build-info-cpp.cmake\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  [6/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600  -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/build-info.cpp\n",
            "  [7/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/common.cpp\n",
            "  [8/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/sampling.cpp\n",
            "  [9/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/console.cpp\n",
            "  [10/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/llama.cpp\n",
            "  [11/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/grammar-parser.cpp\n",
            "  [12/23] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/llava.cpp\n",
            "  [13/23] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/train.cpp\n",
            "  [14/23] /usr/bin/c++  -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/common/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/llava-cli.cpp\n",
            "  [15/23] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -use_fast_math -Wno-pedantic -Xcompiler \"-Wno-array-bounds -Wno-format-truncation -Wextra-semi\" -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o.d -x cu -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/ggml-cuda.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [16/23] : && /usr/bin/g++ -fPIC  -shared -Wl,-soname,libggml_shared.so -o vendor/llama.cpp/libggml_shared.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl -L\"/usr/local/cuda/targets/x86_64-linux/lib/stubs\" -L\"/usr/local/cuda/targets/x86_64-linux/lib\" && :\n",
            "  [17/23] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o vendor/llama.cpp/libllama.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -L/usr/local/cuda/targets/x86_64-linux/lib -Wl,-rpath,/usr/local/cuda-11.8/targets/x86_64-linux/lib:  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl && :\n",
            "  [18/23] : && /tmp/pip-build-env-4q46ugsw/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o && /usr/bin/ranlib vendor/llama.cpp/common/libcommon.a && :\n",
            "  [19/23] : && /tmp/pip-build-env-4q46ugsw/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/libggml_static.a && /usr/bin/ar qc vendor/llama.cpp/libggml_static.a  vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o && /usr/bin/ranlib vendor/llama.cpp/libggml_static.a && :\n",
            "  [20/23] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/. -isystem /usr/local/cuda/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -c /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/vendor/llama.cpp/examples/llava/clip.cpp\n",
            "  [21/23] : && /tmp/pip-build-env-4q46ugsw/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/examples/llava/libllava_static.a && /usr/bin/ar qc vendor/llama.cpp/examples/llava/libllava_static.a  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o && /usr/bin/ranlib vendor/llama.cpp/examples/llava/libllava_static.a && :\n",
            "  [22/23] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllava.so -o vendor/llama.cpp/examples/llava/libllava.so vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o  -Wl,-rpath,/tmp/tmp5mdzz4wf/build/vendor/llama.cpp:/usr/local/cuda-11.8/targets/x86_64-linux/lib:  vendor/llama.cpp/libllama.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libculibos.a  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublasLt.so && :\n",
            "  [23/23] : && /usr/bin/c++ -O3 -DNDEBUG  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -o vendor/llama.cpp/examples/llava/llava-cli  -Wl,-rpath,/tmp/tmp5mdzz4wf/build/vendor/llama.cpp:/usr/local/cuda-11.8/targets/x86_64-linux/lib:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/libllama.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libculibos.a  /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcublasLt.so && :\n",
            "\n",
            "  *** Installing project into wheel...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/lib/libggml_shared.so\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/lib/cmake/Llama/LlamaConfig.cmake\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/lib/cmake/Llama/LlamaConfigVersion.cmake\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/include/ggml.h\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/include/ggml-cuda.h\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/lib/libllama.so\n",
            "  -- Set runtime path of \"/tmp/tmp5mdzz4wf/wheel/platlib/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/include/llama.h\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/bin/convert.py\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/bin/convert-lora-to-ggml.py\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/llama_cpp/libllama.so\n",
            "  -- Set runtime path of \"/tmp/tmp5mdzz4wf/wheel/platlib/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/llama_cpp/libllama.so\n",
            "  -- Set runtime path of \"/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/lib/libllava.so\n",
            "  -- Set runtime path of \"/tmp/tmp5mdzz4wf/wheel/platlib/lib/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/bin/llava-cli\n",
            "  -- Set runtime path of \"/tmp/tmp5mdzz4wf/wheel/platlib/bin/llava-cli\" to \"\"\n",
            "  -- Installing: /tmp/tmp5mdzz4wf/wheel/platlib/llama_cpp/libllava.so\n",
            "  -- Set runtime path of \"/tmp/tmp5mdzz4wf/wheel/platlib/llama_cpp/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/llama_cpp/libllava.so\n",
            "  -- Set runtime path of \"/tmp/pip-install-14goeirt/llama-cpp-python_f4255fd83b9d450e8a4bf71eb3bb403b/llama_cpp/libllava.so\" to \"\"\n",
            "  *** Making wheel...\n",
            "  *** Created llama_cpp_python-0.2.20-cp310-cp310-manylinux_2_35_x86_64.whl...\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.20-cp310-cp310-manylinux_2_35_x86_64.whl size=7138327 sha256=4ff9d7ee7c7b02528f32feb13c069b9d5e43e63b159e1254057bf4f597875746\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t_t5pyi3/wheels/ef/f2/d2/0becb03047a348d7bd9a5b91ec88f4654d6fa7d67ea4e84d43\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.8.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.2\n",
            "    Uninstalling numpy-1.26.2:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.26.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.26.2\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/diskcache-5.6.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/diskcache/\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.2.20\n",
            "    Uninstalling llama_cpp_python-0.2.20:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/__pycache__/convert-lora-to-ggml.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/__pycache__/convert.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/convert-lora-to-ggml.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/convert.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/llava-cli\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/include/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/lib/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/llama_cpp/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/llama_cpp_python-0.2.20.dist-info/\n",
            "      Successfully uninstalled llama_cpp_python-0.2.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.2.20 numpy-1.26.2 typing-extensions-4.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For downloading the models from HF Hub\n",
        "!pip install huggingface_hub --force-reinstall --upgrade --verbose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8lUHQkITZsfc",
        "outputId": "e2bd6cbc-e104-4496-adbd-5ddd1c39b88e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting huggingface_hub\n",
            "  Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "Collecting filelock (from huggingface_hub)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
            "  Using cached fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
            "Collecting requests (from huggingface_hub)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\n",
            "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting packaging>=20.9 (from huggingface_hub)\n",
            "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->huggingface_hub)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->huggingface_hub)\n",
            "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub)\n",
            "  Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->huggingface_hub)\n",
            "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, tqdm, pyyaml, packaging, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface_hub\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.1.0\n",
            "    Uninstalling urllib3-2.1.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/urllib3-2.1.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/urllib3/\n",
            "      Successfully uninstalled urllib3-2.1.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.8.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Removing file or directory /usr/local/bin/tqdm\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/tqdm-4.66.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/tqdm/\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  changing mode of /usr/local/bin/tqdm to 755\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/PyYAML-6.0.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/_yaml/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/yaml/\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/packaging-23.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/packaging/\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/idna-3.6.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/idna/\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.10.0\n",
            "    Uninstalling fsspec-2023.10.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/fsspec-2023.10.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/fsspec/\n",
            "      Successfully uninstalled fsspec-2023.10.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/filelock-3.13.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/filelock/\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Removing file or directory /usr/local/bin/normalizer\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/charset_normalizer-3.3.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/charset_normalizer/\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  changing mode of /usr/local/bin/normalizer to 755\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/certifi-2023.11.17.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/certifi/\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/requests-2.31.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/requests/\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Removing file or directory /usr/local/bin/huggingface-cli\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/huggingface_hub-0.19.4.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/huggingface_hub/\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  changing mode of /usr/local/bin/huggingface-cli to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "datasets 2.15.0 requires fsspec[http]<=2023.10.0,>=2023.1.0, but you have fsspec 2023.12.1 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.1 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.11.17 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2023.12.1 huggingface_hub-0.19.4 idna-3.6 packaging-23.2 pyyaml-6.0.1 requests-2.31.0 tqdm-4.66.1 typing-extensions-4.8.0 urllib3-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For downloading datasets\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLKn3N_uaT45",
        "outputId": "b1880ce7-6b6c-476a-ec12-f82f5c94aac9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets)\n",
            "  Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.12.1\n",
            "    Uninstalling fsspec-2023.12.1:\n",
            "      Successfully uninstalled fsspec-2023.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2023.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the hf_hub_download function from the Hugging Face Hub library\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Import the Llama class from the llama_cpp library\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "IuH8FlPxbQi_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
        "model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\" # the model is in gguf format"
      ],
      "metadata": {
        "id": "OA7iIsV3bfzA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        ")"
      ],
      "metadata": {
        "id": "SEaWU_UQb2dD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # 512 - Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=43, # 43 - Change this value based on your model and your GPU VRAM pool.\n",
        "    n_ctx=4096, # Context window\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtBixHxxc4J_",
        "outputId": "5245545e-1737-4776-d3dc-46d439a03bb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the random module for generating random numbers or choices.\n",
        "import random\n",
        "\n",
        "# Import the pandas library and alias it as 'pd' for easier use.\n",
        "import pandas as pd\n",
        "\n",
        "# Import the 'load_dataset' function from the 'datasets' library for loading datasets.\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "nXMraUPhdlJc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset using the 'load_dataset' function\n",
        "dataset = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "c1slly3fdp4y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_train_df = dataset['train'].to_pandas()   ## Tto_pandas is used to convert the training data into a pandas DataFrame.\n",
        "imdb_test_df = dataset['test'].to_pandas()  ##: It converts the testing data into another pandas DataFrame."
      ],
      "metadata": {
        "id": "lLPnH-t_eE8c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(imdb_train_df.shape, imdb_test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrXZNFqeeIOF",
        "outputId": "e874cf1d-eee1-46b5-bf0b-44ed6d71e51f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 2), (25000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_examples = imdb_train_df.loc[imdb_train_df.label == 1, :].sample(3)\n",
        "negative_examples = imdb_train_df.loc[imdb_train_df.label == 0, :].sample(3)"
      ],
      "metadata": {
        "id": "T6RDtiUQeUId"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "-LQKoPkVeYVT",
        "outputId": "9746dc7c-3429-4fa1-d625-a6d7c2fdc02f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "17265  For anyone who wishes to get an impression of ...      1\n",
              "14881  It was such a treat when this show was on beca...      1\n",
              "18588  I claim no matter how hard I seek I'll never f...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cce08381-33b2-4580-b0bf-0f9237969525\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17265</th>\n",
              "      <td>For anyone who wishes to get an impression of ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14881</th>\n",
              "      <td>It was such a treat when this show was on beca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18588</th>\n",
              "      <td>I claim no matter how hard I seek I'll never f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cce08381-33b2-4580-b0bf-0f9237969525')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cce08381-33b2-4580-b0bf-0f9237969525 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cce08381-33b2-4580-b0bf-0f9237969525');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecff2b45-76ab-4ae4-b62b-a22cdc08cd10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecff2b45-76ab-4ae4-b62b-a22cdc08cd10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecff2b45-76ab-4ae4-b62b-a22cdc08cd10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "xqTRiB3iegDn",
        "outputId": "a07642d0-ea93-4e70-8df4-a0f2f658a097"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "149   This film was choppy, incoherent and contrived...      0\n",
              "4094  I'm writing this because I somehow felt being ...      0\n",
              "2884  This is the biggest piece of crap ever. It loo...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df2f777f-f824-4b3d-81a1-819c91ecdbf8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>This film was choppy, incoherent and contrived...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>I'm writing this because I somehow felt being ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2884</th>\n",
              "      <td>This is the biggest piece of crap ever. It loo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df2f777f-f824-4b3d-81a1-819c91ecdbf8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df2f777f-f824-4b3d-81a1-819c91ecdbf8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df2f777f-f824-4b3d-81a1-819c91ecdbf8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3bf96f4-b3a4-4479-8083-c4294fb36b93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3bf96f4-b3a4-4479-8083-c4294fb36b93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3bf96f4-b3a4-4479-8083-c4294fb36b93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenating the subsets of positive and negative sentiment examples (positive_examples and negative_examples)\n",
        "examples = pd.concat([positive_examples, negative_examples]).to_json(orient='records')\n",
        "\n",
        "#After concatenating the DataFrames, the to_json() method is applied to convert the combined DataFrame into a JSON (JavaScript Object Notation) format.\n",
        "#The orient='records' argument specifies the format in which the JSON data should be structured."
      ],
      "metadata": {
        "id": "NcUWTW8Ter-O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "mFccaMhseuXB",
        "outputId": "6400e4a2-453e-4489-95b7-0d3de4f77a99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[{\"text\":\"For anyone who wishes to get an impression of the Soviet view of modern Russian history this monumental film is a treasure. The story starts at the turn of the century (1900) in the yellowish sepia colours of old photographs which improves to black and white during the middle of the century and to full colour when the story approaches modern times (i.e. the 1960s).<br \\\\/><br \\\\/>The story focuses on a boy in a remote Siberian village, who is marked by the arrival and arrest of an anarchist during the czarist era. He later joins the Bolsheviks after the revolution and brings soviet communism to his village. His son, by the local beauty, fights the Germans during the Second World War. When he returns to the village, the oil industry takes off and we are treated to some Soviet economic idealism.<br \\\\/><br \\\\/>This film is long and slow, but utterly logic and very well made. It can be seen in three parts.\",\"label\":1},{\"text\":\"It was such a treat when this show was on because it was such a fresh, innovative, and original show. This makes every show I\\'ve ever watched look plain boring. The moment the first episode aired I was entranced and I became attached to all the characters so easy (which usually never happens because I always hate a few characters). It is a pity this show won\\'t have a third season, because it has to be one of the best shows I have ever seen and that isn\\'t exaggerating my feelings for the show at all. Nothing can ever replace Pushing Daisies, because what could ABC possibly find to replace this show? This is easily the best show on television. <br \\\\/><br \\\\/>I came for Kristin Chenoweth and I stayed because I fell in love with the entire show.\",\"label\":1},{\"text\":\"I claim no matter how hard I seek I\\'ll never find a better movie version of \\\\\"Othello\\\\\". If you love Kenneth Branagh\\'s magnificent masterpieces \\\\\"Much ado about nothing\\\\\" (1993) and \\\\\"Hamlet\\\\\" (1996) as much as I do I\\'m dead certain you\\'ll also find Oliver Parker\\'s \\\\\"Othello\\\\\" irresistible. Laurence Fishburne has been in a various splendid roles during his career. He was quite terrific in \\\\\"Boys n the hood\\\\\" (1991) - I\\'ve always considered his amusing role of Furious Styles as his very greatest achievement. That was, of course, way before I saw this.<br \\\\/><br \\\\/>He plays the part of Othello and he is probably in the most challenging role of his whole career but he does a brilliant, fantastic job. Ir\\\\u00e8ne Jacob is absolutely charming Desdemona and Kenneth Branagh is just simply phenomenal in a most fascinating role of the story\\'s crooked, manipulate villain Iago. Marvelous \\\\\"Othello\\\\\" is part of the absolute elite among Shakespeare\\'s ingenious works. It deals with his favorite topics: crookedness, envy, deceitfulness and jealousy. This movie adaptation is certainly one of the finest films I\\'ve seen that\\'s based on William Shakespeare\\'s plays.\",\"label\":1},{\"text\":\"This film was choppy, incoherent and contrived. It was also an extremely mean-spirited portrayal of women. I rented it because it was listed as a comedy (that\\'s a stretch), and because the cover said Andie McDowell was acting up a storm in it. She wasn\\'t. I\\'m a gal, I watched this film with two guys, and we spent an hour afterwards exclaiming over how bad it was.<br \\\\/><br \\\\/>WARNING: PLOT SUMMARY BELOW! RAMPANT SPOILERS!<br \\\\/><br \\\\/>The movie starts out with a fairly hackneyed plot about an older woman who takes up with a younger man, to the severe disapproval of her two jealous single girlfriends. They want her to marry a boring guy their own age who is kind of in love with her. But she\\'s so happy with her oversexed puppy that you\\'re rooting for them to stick it out, and sure enough, she decides to marry the guy. But her harpy girlfriend, aided by the wishy-washy one, sets up a plot to trick our heroine into thinking the guy is cheating on her. It works. She has a fight with him, he runs out of the house and is crushed by a truck (Remember the movie\\'s title?) So now he\\'s dead, two-thirds of the way through the film. And although our heroine is a school headmistress who spends her time watching over girls, she apparently forgot to use birth control and is pregnant.<br \\\\/><br \\\\/>She\\'s already broken off relations with her girlfriends, because they were so unsupportive. Alone and pitiful, she decides to marry the boring guy. Did I mention that the boring guy who kind of loves her is a minister? She had asked him to marry her to the young guy (nice, huh?), but now she tells him she\\'ll marry him, and apparently he has no objections to being dicked around in this fashion. But her girlfriends rescue her at the altar and take her home, where they not-quite-confess that they were mostly responsible for the love of her life getting smushed. She has the kid. In the final scene, they leave it in a crib inside her house while they go out on the porch to drink, smoke and be smug. I kid you not, it\\'s that bad. I left out the part about the cancer red-herring and the harpy\\'s ridiculous lesbian moment.\",\"label\":0},{\"text\":\"I\\'m writing this because I somehow felt being led to believe Dark Remains was a good movie. Whilst it\\'s not the worst I\\'ve seen, it certainly isn\\'t good.<br \\\\/><br \\\\/>A Weak script, weak actors, and weak directing. Even if they can\\'t afford big name cast, would it be too much to ask for a more attractive lead actress? It was painful to watch a plain actress through out the film with her dull performance. The story was a clich\\\\u00e9 and poorly scripted. The special effects were minimal. The \\\\\"suspense\\\\\" tricks employed repetitively here were hard to swallow.<br \\\\/><br \\\\/>To be fair, Dark Remains is no worse than quite some of the Masters of Horrors\\' episodes. But not quite on par with quality movies yet. Dark Remains is only recommended for the hardcore horror fans who don\\'t want to miss any movie in the genre, even if it\\'s a poorly made one. As for anyone else, time should be spent on something more valuable - which should be extremely easy.\",\"label\":0},{\"text\":\"This is the biggest piece of crap ever. It looks like they spent more time, effort, and money making the DVD cover than they did on the actual movie. I really thought the DVD had been switched out with someone\\'s homemade porno until I recognized one of the actors from the cover. This movie looks like someone made it with a hundred bucks and a camcorder and they spent half of that on rats. The picture is really clear, but that, along with the very unfortunate lighting, cinematography, if you can call it that, production, acting, if that is actually what they are doing, and script, if they had one, makes this movie look worse than an old porno. At least the old porno has a point. This just looks like some PETA members got together and decided to make a really disturbing, pointless PSA about animals rights and feelings. This is so not worth the money or the time. It has nothing in common with the actual BTK serial killer other than the name of the killer and that of some of the victims. The people who made this movie should be glad he\\'s not still free, or he might have come after them just for screwing up this movie so bad.\",\"label\":0}]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the 'json' module for handling JSON data.\n",
        "import json\n",
        "\n",
        "# Import the 'numpy' library and alias it as 'np' for convenience.\n",
        "import numpy as np\n",
        "\n",
        "# Import the 'Counter' class from the 'collections' module for counting occurrences of elements.\n",
        "from collections import Counter\n",
        "\n",
        "# Import 'tqdm' for displaying progress bars when iterating over data.\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "PcReDtGOfUQe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"[INST]<<SYS>>Classify the sentiment of movie reviews presented in the input as 'positive' or 'negative'.\n",
        "Movie reviews will be delimited by triple backticks in the input.\n",
        "Answer only 'positive' or 'negative'. Do not explain your answer.\n",
        "\n",
        "Instructions:\n",
        "1. Carefully read the text of the review and consider the overall sentiment of the review\n",
        "2. Estimate the probability of the review being positive\n",
        "\n",
        "To re-iterate, your answer should strictly only contain the label: positive or negative.\n",
        "\n",
        "Some examples of expected output are provided below as guidance.<</SYS>>[/INST]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pqwpmlgdf_GQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "[INST] ```{input_data}``` [/INST]\n",
        "{output}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FFAU5DJLgB6t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize an empty string to store few-shot examples\n",
        "few_shot_examples = ''"
      ],
      "metadata": {
        "id": "k_bI4mUmgGVm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Iterate through each example in the JSON data which was created earlier\n",
        "for example in json.loads(examples):\n",
        "        # Extract the input data (text) from the example, excluding the 'label'\n",
        "\n",
        "    example_input = {i:example[i] for i in example if i!='label'}\n",
        "    # Determine the sentiment prediction based on the 'label' value\n",
        "    if example['label'] == 0:\n",
        "        example_prediction = 'negative'\n",
        "    else:\n",
        "        example_prediction = 'positive'\n",
        "\n",
        "    # Concatenate the input data and the predicted sentiment\n",
        "    # using a template and add it to the 'few_shot_examples' string\n",
        "\n",
        "    few_shot_examples += prompt_template.format(\n",
        "        input_data=example_input['text'],  ###input_data is used in the prompt_template\n",
        "        output=example_prediction          ###outpu is used in the prompt_template\n",
        "    )"
      ],
      "metadata": {
        "id": "K5mpHhGxg3vs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_rows = json.loads(\n",
        "    imdb_test_df.sample(100).to_json(orient='records')\n",
        ")"
      ],
      "metadata": {
        "id": "aXshUrHihCwk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialize empty lists to store model predictions and ground truth values.\n",
        "model_predictions, ground_truths = [], []"
      ],
      "metadata": {
        "id": "zF1QEXtbkXWy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Iterate through each row in the test data with a progress bar\n",
        "for row in tqdm(test_rows):\n",
        "      # Extract the input data (text) from the current row, excluding the 'label'\n",
        "    test_input = {i:row[i] for i in row if i!='label'}\n",
        "\n",
        "        # Construct a few-shot prompt by combining system message, few-shot examples, and test input\n",
        "    few_shot_prompt = (\n",
        "        system_message + few_shot_examples +\n",
        "        prompt_template.format(\n",
        "            input_data=test_input['text'],\n",
        "            output=''\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # print(few_shot_prompt)\n",
        "\n",
        "    try:\n",
        "        # Use the model (lcpp_llm) to generate a response based on the few-shot prompt\n",
        "        response = lcpp_llm(\n",
        "            prompt=few_shot_prompt,\n",
        "            max_tokens=2,\n",
        "            temperature=0,\n",
        "            top_p=0.95,\n",
        "            repeat_penalty=1.2,\n",
        "            top_k=50,\n",
        "            stop=['INST'], # Dynamic stopping when such token is detected.\n",
        "            echo=False # do not return the prompt\n",
        "        )\n",
        "        # Extract the model's prediction from the response\n",
        "\n",
        "        prediction = response[\"choices\"][0][\"text\"]\n",
        "\n",
        "        # Append the model's prediction to the 'model_predictions' list, lowercased and stripped of whitespace\n",
        "        model_predictions.append(prediction.strip().lower())\n",
        "\n",
        "        # Determine the ground truth label based on the row's 'label' value and append it to 'ground_truths'\n",
        "        if row['label'] == 0:\n",
        "            ground_truths.append('negative')\n",
        "        else:\n",
        "            ground_truths.append('positive')\n",
        "    except ValueError as e:\n",
        "          # Handle any ValueErrors that may occur during the process and continue with the next row\n",
        "\n",
        "        print(e)\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l45csysAhfvG",
        "outputId": "ac55e629-62ef-4c87-9d22-9ac205dd1e8e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
            "  1%|          | 1/100 [00:01<02:08,  1.30s/it]Llama.generate: prefix-match hit\n",
            "  2%|▏         | 2/100 [00:02<01:45,  1.08s/it]Llama.generate: prefix-match hit\n",
            "  3%|▎         | 3/100 [00:03<01:36,  1.00it/s]Llama.generate: prefix-match hit\n",
            "  4%|▍         | 4/100 [00:04<01:37,  1.02s/it]Llama.generate: prefix-match hit\n",
            "  5%|▌         | 5/100 [00:06<02:19,  1.47s/it]Llama.generate: prefix-match hit\n",
            "  6%|▌         | 6/100 [00:07<02:06,  1.34s/it]Llama.generate: prefix-match hit\n",
            "  7%|▋         | 7/100 [00:08<01:43,  1.11s/it]Llama.generate: prefix-match hit\n",
            "  8%|▊         | 8/100 [00:09<01:45,  1.15s/it]Llama.generate: prefix-match hit\n",
            "  9%|▉         | 9/100 [00:11<02:01,  1.34s/it]Llama.generate: prefix-match hit\n",
            " 10%|█         | 10/100 [00:12<02:00,  1.34s/it]Llama.generate: prefix-match hit\n",
            " 11%|█         | 11/100 [00:13<02:00,  1.35s/it]Llama.generate: prefix-match hit\n",
            " 12%|█▏        | 12/100 [00:14<01:46,  1.21s/it]Llama.generate: prefix-match hit\n",
            " 13%|█▎        | 13/100 [00:17<02:18,  1.59s/it]Llama.generate: prefix-match hit\n",
            " 14%|█▍        | 14/100 [00:18<01:59,  1.39s/it]Llama.generate: prefix-match hit\n",
            " 15%|█▌        | 15/100 [00:19<01:47,  1.26s/it]Llama.generate: prefix-match hit\n",
            " 16%|█▌        | 16/100 [00:21<02:13,  1.59s/it]Llama.generate: prefix-match hit\n",
            " 17%|█▋        | 17/100 [00:23<02:17,  1.66s/it]Llama.generate: prefix-match hit\n",
            " 18%|█▊        | 18/100 [00:24<01:57,  1.43s/it]Llama.generate: prefix-match hit\n",
            " 19%|█▉        | 19/100 [00:25<01:49,  1.35s/it]Llama.generate: prefix-match hit\n",
            " 20%|██        | 20/100 [00:26<01:52,  1.40s/it]Llama.generate: prefix-match hit\n",
            " 21%|██        | 21/100 [00:30<02:32,  1.94s/it]Llama.generate: prefix-match hit\n",
            " 22%|██▏       | 22/100 [00:33<03:04,  2.37s/it]Llama.generate: prefix-match hit\n",
            " 23%|██▎       | 23/100 [00:35<02:52,  2.24s/it]Llama.generate: prefix-match hit\n",
            " 24%|██▍       | 24/100 [00:36<02:16,  1.80s/it]Llama.generate: prefix-match hit\n",
            " 25%|██▌       | 25/100 [00:38<02:33,  2.04s/it]Llama.generate: prefix-match hit\n",
            " 26%|██▌       | 26/100 [00:39<02:08,  1.74s/it]Llama.generate: prefix-match hit\n",
            " 27%|██▋       | 27/100 [00:43<02:49,  2.32s/it]Llama.generate: prefix-match hit\n",
            " 28%|██▊       | 28/100 [00:45<02:36,  2.17s/it]Llama.generate: prefix-match hit\n",
            " 29%|██▉       | 29/100 [00:46<02:07,  1.79s/it]Llama.generate: prefix-match hit\n",
            " 30%|███       | 30/100 [00:47<02:02,  1.75s/it]Llama.generate: prefix-match hit\n",
            " 31%|███       | 31/100 [00:51<02:33,  2.23s/it]Llama.generate: prefix-match hit\n",
            " 32%|███▏      | 32/100 [00:52<02:16,  2.01s/it]Llama.generate: prefix-match hit\n",
            " 33%|███▎      | 33/100 [00:56<02:54,  2.61s/it]Llama.generate: prefix-match hit\n",
            " 34%|███▍      | 34/100 [00:57<02:19,  2.12s/it]Llama.generate: prefix-match hit\n",
            " 35%|███▌      | 35/100 [00:59<02:04,  1.92s/it]Llama.generate: prefix-match hit\n",
            " 36%|███▌      | 36/100 [01:00<01:54,  1.80s/it]Llama.generate: prefix-match hit\n",
            " 37%|███▋      | 37/100 [01:01<01:38,  1.56s/it]Llama.generate: prefix-match hit\n",
            " 38%|███▊      | 38/100 [01:02<01:29,  1.45s/it]Llama.generate: prefix-match hit\n",
            " 39%|███▉      | 39/100 [01:04<01:27,  1.43s/it]Llama.generate: prefix-match hit\n",
            " 40%|████      | 40/100 [01:05<01:16,  1.28s/it]Llama.generate: prefix-match hit\n",
            " 41%|████      | 41/100 [01:06<01:17,  1.31s/it]Llama.generate: prefix-match hit\n",
            " 42%|████▏     | 42/100 [01:08<01:31,  1.58s/it]Llama.generate: prefix-match hit\n",
            " 43%|████▎     | 43/100 [01:09<01:24,  1.48s/it]Llama.generate: prefix-match hit\n",
            " 44%|████▍     | 44/100 [01:13<02:04,  2.23s/it]Llama.generate: prefix-match hit\n",
            " 45%|████▌     | 45/100 [01:16<02:04,  2.26s/it]Llama.generate: prefix-match hit\n",
            " 46%|████▌     | 46/100 [01:18<02:06,  2.34s/it]Llama.generate: prefix-match hit\n",
            " 47%|████▋     | 47/100 [01:19<01:42,  1.93s/it]Llama.generate: prefix-match hit\n",
            " 48%|████▊     | 48/100 [01:20<01:19,  1.53s/it]Llama.generate: prefix-match hit\n",
            " 49%|████▉     | 49/100 [01:21<01:17,  1.52s/it]Llama.generate: prefix-match hit\n",
            " 50%|█████     | 50/100 [01:22<01:06,  1.34s/it]Llama.generate: prefix-match hit\n",
            " 51%|█████     | 51/100 [01:24<01:15,  1.55s/it]Llama.generate: prefix-match hit\n",
            " 52%|█████▏    | 52/100 [01:25<01:03,  1.32s/it]Llama.generate: prefix-match hit\n",
            " 53%|█████▎    | 53/100 [01:27<01:13,  1.57s/it]Llama.generate: prefix-match hit\n",
            " 54%|█████▍    | 54/100 [01:28<01:03,  1.37s/it]Llama.generate: prefix-match hit\n",
            " 55%|█████▌    | 55/100 [01:29<00:57,  1.28s/it]Llama.generate: prefix-match hit\n",
            " 56%|█████▌    | 56/100 [01:31<00:57,  1.30s/it]Llama.generate: prefix-match hit\n",
            " 57%|█████▋    | 57/100 [01:32<00:54,  1.26s/it]Llama.generate: prefix-match hit\n",
            " 58%|█████▊    | 58/100 [01:33<00:54,  1.30s/it]Llama.generate: prefix-match hit\n",
            " 59%|█████▉    | 59/100 [01:34<00:48,  1.18s/it]Llama.generate: prefix-match hit\n",
            " 60%|██████    | 60/100 [01:35<00:45,  1.13s/it]Llama.generate: prefix-match hit\n",
            " 61%|██████    | 61/100 [01:37<00:55,  1.43s/it]Llama.generate: prefix-match hit\n",
            " 62%|██████▏   | 62/100 [01:38<00:45,  1.20s/it]Llama.generate: prefix-match hit\n",
            " 63%|██████▎   | 63/100 [01:39<00:43,  1.19s/it]Llama.generate: prefix-match hit\n",
            " 64%|██████▍   | 64/100 [01:40<00:45,  1.27s/it]Llama.generate: prefix-match hit\n",
            " 65%|██████▌   | 65/100 [01:42<00:42,  1.22s/it]Llama.generate: prefix-match hit\n",
            " 66%|██████▌   | 66/100 [01:43<00:44,  1.31s/it]Llama.generate: prefix-match hit\n",
            " 67%|██████▋   | 67/100 [01:45<00:49,  1.51s/it]Llama.generate: prefix-match hit\n",
            " 68%|██████▊   | 68/100 [01:46<00:42,  1.33s/it]Llama.generate: prefix-match hit\n",
            " 69%|██████▉   | 69/100 [01:47<00:41,  1.33s/it]Llama.generate: prefix-match hit\n",
            " 70%|███████   | 70/100 [01:48<00:35,  1.18s/it]Llama.generate: prefix-match hit\n",
            " 71%|███████   | 71/100 [01:49<00:33,  1.16s/it]Llama.generate: prefix-match hit\n",
            " 72%|███████▏  | 72/100 [01:51<00:33,  1.20s/it]Llama.generate: prefix-match hit\n",
            " 73%|███████▎  | 73/100 [01:52<00:36,  1.35s/it]Llama.generate: prefix-match hit\n",
            " 74%|███████▍  | 74/100 [01:53<00:30,  1.18s/it]Llama.generate: prefix-match hit\n",
            " 75%|███████▌  | 75/100 [01:54<00:27,  1.10s/it]Llama.generate: prefix-match hit\n",
            " 76%|███████▌  | 76/100 [01:56<00:33,  1.39s/it]Llama.generate: prefix-match hit\n",
            " 77%|███████▋  | 77/100 [01:58<00:32,  1.42s/it]Llama.generate: prefix-match hit\n",
            " 78%|███████▊  | 78/100 [01:58<00:27,  1.24s/it]Llama.generate: prefix-match hit\n",
            " 79%|███████▉  | 79/100 [01:59<00:24,  1.15s/it]Llama.generate: prefix-match hit\n",
            " 80%|████████  | 80/100 [02:00<00:21,  1.09s/it]Llama.generate: prefix-match hit\n",
            " 81%|████████  | 81/100 [02:01<00:19,  1.04s/it]Llama.generate: prefix-match hit\n",
            " 82%|████████▏ | 82/100 [02:02<00:18,  1.00s/it]Llama.generate: prefix-match hit\n",
            " 83%|████████▎ | 83/100 [02:03<00:18,  1.08s/it]Llama.generate: prefix-match hit\n",
            " 84%|████████▍ | 84/100 [02:05<00:17,  1.10s/it]Llama.generate: prefix-match hit\n",
            " 85%|████████▌ | 85/100 [02:06<00:17,  1.18s/it]Llama.generate: prefix-match hit\n",
            " 86%|████████▌ | 86/100 [02:08<00:22,  1.57s/it]Llama.generate: prefix-match hit\n",
            " 87%|████████▋ | 87/100 [02:09<00:18,  1.42s/it]Llama.generate: prefix-match hit\n",
            " 88%|████████▊ | 88/100 [02:10<00:15,  1.27s/it]Llama.generate: prefix-match hit\n",
            " 89%|████████▉ | 89/100 [02:13<00:18,  1.66s/it]Llama.generate: prefix-match hit\n",
            " 90%|█████████ | 90/100 [02:14<00:15,  1.51s/it]Llama.generate: prefix-match hit\n",
            " 91%|█████████ | 91/100 [02:19<00:21,  2.43s/it]Llama.generate: prefix-match hit\n",
            " 92%|█████████▏| 92/100 [02:19<00:15,  1.91s/it]Llama.generate: prefix-match hit\n",
            " 93%|█████████▎| 93/100 [02:21<00:12,  1.77s/it]Llama.generate: prefix-match hit\n",
            " 94%|█████████▍| 94/100 [02:22<00:10,  1.68s/it]Llama.generate: prefix-match hit\n",
            " 95%|█████████▌| 95/100 [02:24<00:09,  1.83s/it]Llama.generate: prefix-match hit\n",
            " 96%|█████████▌| 96/100 [02:26<00:06,  1.67s/it]Llama.generate: prefix-match hit\n",
            " 97%|█████████▋| 97/100 [02:29<00:06,  2.11s/it]Llama.generate: prefix-match hit\n",
            " 98%|█████████▊| 98/100 [02:30<00:03,  1.90s/it]Llama.generate: prefix-match hit\n",
            " 99%|█████████▉| 99/100 [02:31<00:01,  1.60s/it]Llama.generate: prefix-match hit\n",
            "100%|██████████| 100/100 [02:32<00:00,  1.52s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(model_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prZIwdn0OKYE",
        "outputId": "cfef4a62-285c-4530-c095-9c7493990465"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 43, 'positive': 55, 'the sentiment': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(ground_truths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hwOWZPdZpad",
        "outputId": "2e4e5291-4610-4a83-8f7f-94e732ca10cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 46, 'positive': 54})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truths = np.array(ground_truths)\n",
        "model_predictions = np.array(model_predictions)\n",
        "\n",
        "\n",
        "#ground_truths contains the true labels (ground truth) for a set of examples.\n",
        "#model_predictions contains the labels predicted by a machine learning model for the same set of examples."
      ],
      "metadata": {
        "id": "xeQ-yC_AZvq_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(ground_truths == model_predictions).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT_GUllNZ3Li",
        "outputId": "a0e5b0c7-2e9c-4c01-b1c2-7cb2ed9681a3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TP = ((model_predictions == 'positive') & (ground_truths == 'positive')).sum()\n",
        "FP = ((model_predictions == 'positive') & (ground_truths == 'negative')).sum()\n",
        "precision = TP / (TP+FP)"
      ],
      "metadata": {
        "id": "4oDCUUWIZ8YR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXYF6MOOZ_Bh",
        "outputId": "c7df7f6c-2541-4cee-a08c-56fb1c22dd83"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9272727272727272"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"AdiOO7/Bank_Complaints\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "2fc62504ca9c4eb2ac530e0fb2389973",
            "ea7b9ba62b744c51879e0a7bd3e0c14e",
            "46372b53e2dd4cdc8d25db970debb51b",
            "f1e6f64e6ef14689bcf2656630fe2eb5",
            "4400cf0419f94527b76ac4b64ea18c79",
            "749e1276e4414f18b5b9af6c38f29040",
            "d1e70ab44eee41928211f968f3893302",
            "f26324a4d7254759856e17965f2f5101",
            "2ef0c0b059dc46919ef2ba2132a60ca9",
            "3223306c0d094e19830190e98e17989f",
            "03248dc2255b47a38bb36d39bc09d2ef",
            "6e37973091c2420ab80d56d7f814dd54",
            "aad7221a39014ae7a01adb3d866d6408",
            "b8ed48821a944883a32865dd8e80137e",
            "dfc14e3802b846ba9bc22e9ef1c716d4",
            "5ad2131f24d9442dbff862b0b80cf0c4",
            "cfd6a9f9a24a4b89addcced88d93f9be",
            "4f2edd2378ef4422b11dd91ba53a19f9",
            "cf399954c96543ba8308c7479c8fd1bd",
            "d6e2d09207e74d508376ba3cffc722a9",
            "a05e87c2c7b7496aa88402b98813b842",
            "088c9972e64c41c1b5a51c65d3d1a71e",
            "2902de7d80cf475593fcb96c098aa5ac",
            "9694644a73fc497288eb9929e2eafad2",
            "523e3372b0e54633a9c54e1dc1b37e77",
            "78f672bf20fb410d964bf182228d5df0",
            "191bae36632148df8f2302fb65c4cb28",
            "79df90f29557483988d34ee894e2615c",
            "41ae958052914c53bc907878f7d8f93c",
            "a2f4c0d4c48246eaac1fb2c36e5b7fe4",
            "0037130516cd49ebb0728ec2a2d0ab65",
            "3cc5601a49974304b9e0a5e202faf7b9",
            "f20f1857cc0e43ada30fb2ea4b101658",
            "fb6cb044f69b4ad48ec7ab525e502edc",
            "28687bcca26d4581bfd9fc4aec24082a",
            "0d35ccdb42b846358a5c2410ba6a3b83",
            "fd5b6f78b7fe458fbae87b62923a8b82",
            "b36f6c2c0f4040cbbcf449ca66e57c8f",
            "3c74d2a067e1423caacff501f9ef4474",
            "2a7f2e3bda504cbea898192fb706b975",
            "9050dd3f58fd48eab49b8566ca88132d",
            "ec89f248d9a64d92bba35bfc6c51d853",
            "ccf2e316f37f49229752e5bf222b7dbf",
            "e2b77886de8d49438c598e0281b0d262",
            "4d5e0ea697004a81972b3c555e67cad8",
            "c5af083084c840b4ae41f4b16cd5119b",
            "917cf549102e4a6ea7cf16466e4d76b0",
            "781008e1a4f74e05a99e44a728ee496e",
            "7aba4e90ffe84c6f9979838895f7a321",
            "dafd43f3a2e64894bc95a96eba4b6c81",
            "0d0378148be049979e813e0e6dcd6a30",
            "ac3299d0fed249cc9ec3e71fd0a00256",
            "8410dcd185f24f5f8f1f14dbbadc30b2",
            "99d061e3b5c240159627f8d520422373",
            "6c0cba6bccec4df9bbd826b1de54bd8f"
          ]
        },
        "id": "iVk3CjUTbYpF",
        "outputId": "f477f2c3-5dba-46dd-d2bb-8732d596ee73"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/130 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fc62504ca9c4eb2ac530e0fb2389973"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e37973091c2420ab80d56d7f814dd54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/573k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2902de7d80cf475593fcb96c098aa5ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb6cb044f69b4ad48ec7ab525e502edc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d5e0ea697004a81972b3c555e67cad8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"[INST]<<SYS>>As a spokesperson person of a particular bank, you are tasked to give a public response to a user's complaint presented as input.\n",
        "Instructions:\n",
        "1. Carefully observe the intensity and severity of the complaint received as input.\n",
        "2. Choose a carefully worded public response. You need to reply to every complaint, however, responding with \"Company chooses not to provide a public response\" is also a valid response.\n",
        "Some examples of appropriate response are provided below as guidance.<</SYS>>[/INST]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Br97ekembc4m"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "[INST] {input_example} [/INST]\n",
        "{output_example}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7_EYbOd-b4zo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_examples = ''"
      ],
      "metadata": {
        "id": "iB2Tggl8b7IC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    sample_document = dataset['train'][random.randint(0, 1829)]\n",
        "    user_input_example = sample_document['Input']\n",
        "    assistant_output_example = sample_document['Response']\n",
        "\n",
        "    few_shot_examples += prompt_template.format(\n",
        "        input_example=user_input_example,\n",
        "        output_example=assistant_output_example\n",
        "    )"
      ],
      "metadata": {
        "id": "oqztMffwb97y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_document = dataset['train'][random.randint(0, 1829)]\n",
        "new_complaint = test_document['Input']"
      ],
      "metadata": {
        "id": "wziwVn-2cAyb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = (\n",
        "    system_message +\n",
        "    few_shot_examples +\n",
        "    prompt_template.format(\n",
        "        input_example=new_complaint,\n",
        "        output_example=''\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "DkTYC5ONcDeT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=few_shot_prompt,\n",
        "    max_tokens=256,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    top_k=50,\n",
        "    stop=['INST'], # Dynamic stopping when such token is detected.\n",
        "    echo=False # do not return the prompt\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YClylzccGnn",
        "outputId": "8a5492ba-15e3-49ab-a77f-122226d47859"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_complaint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XbQYZ2JgcKUm",
        "outputId": "be8eb761-d2c8-4297-d82f-723056600861"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bank of America reduced my credit card limit, damaging my credit while I paid my out my amount in full and being a good payment \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9h5HO6JcQoN",
        "outputId": "27d8bb95-dfd0-43d1-e054-8b7a87f8bcf7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company believes it acted appropriately as authorized by contract or law. However, we value our customers' satisfaction and would like to discuss this matter further with you. Please contact us at your earliest convenience so that we can work towards resolving the issue amicably.\n"
          ]
        }
      ]
    }
  ]
}